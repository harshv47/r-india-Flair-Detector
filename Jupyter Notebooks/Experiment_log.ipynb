{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiment log.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNklptdQQDbzIK20CpcRj6S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshv47/r-india-Flair-Detector/blob/master/Jupyter%20Notebooks/Experiment_log.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf3GDRk5Zv8b",
        "colab_type": "text"
      },
      "source": [
        "###This log is divided into topics and in each topic the logs are sorted using time, so lower will have been written later in time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojOgDq9sTGGX",
        "colab_type": "text"
      },
      "source": [
        "# Importing\n",
        "At first I imported common libraries.\n",
        "\n",
        "These are used on every project so it's common.\n",
        "\n",
        "Although this one has long texts, so maybe addional importing may be required"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qEReMUuTePY",
        "colab_type": "text"
      },
      "source": [
        "# Downloading the Dataset\n",
        "To download the dataset, I used praw. However, it takes quite a while to download and I can't just press Ctrl + F8 to run all cells before anymore after every runtime restart.\n",
        "\n",
        "So, to avoid the hassle I used a separate python file that is stored in */dataset/procure.py* to download data.\n",
        "\n",
        "I have worked with praw before so I rehashed some previous code, also since this will go on GitHub and I might forget to remove sensitive details I have used a file to store the credential on local storage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2QwRJHMUs_y",
        "colab_type": "text"
      },
      "source": [
        "At first I downloaded the dataset by sorting r/india by hot. However, the dataset was really bias, I could not even get any examples for some flairs.\n",
        "\n",
        "So, then I iterated and sorted by each flair. This was a better method.\n",
        "\n",
        "I downloaded 100 examples for each flair."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fn6iPOtVoGu",
        "colab_type": "text"
      },
      "source": [
        "There was an issue with the comments. Initially I did not want to include them because I thought it would be a hassle since some posts have thousands of comments it would be unwieldy to go through all that.\n",
        "\n",
        "Later, I included comments because it was very valuable information for determining flairs. Eg. on many Political flairs one could see that many political party names and people were written in the comments and similarly, for Science flair ISRO and other Scientific orgs were routinely mentioned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmHhDY9sY6Yk",
        "colab_type": "text"
      },
      "source": [
        "After running the models, I surmised that some models may be overfitting quite a lot. To counter this I increased the size of the dataset. Increasing the limit to 500."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQhb0tXhW28P",
        "colab_type": "text"
      },
      "source": [
        "# Importing the Dataset\n",
        "The dataset was imported using *pd.read_csv*\n",
        "\n",
        "I prefer quantitative data to representations, so I looked at shape, dtypes, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP3hCJahYNZR",
        "colab_type": "text"
      },
      "source": [
        "The download was 100 examples for each flairs, and everyone had 100 except [R]eddiquette.\n",
        "\n",
        "That might be a problem for that class, as the algorithm would naturally be less good at predicting for that class now.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-yZZIQEZdUn",
        "colab_type": "text"
      },
      "source": [
        "Even though the limit is 500, the highest number of examples was only 248, meaning I have exhausted all the post for that flair type.\n",
        "\n",
        "This would also mean that now classifiers will perform worse for [R]eddiquette class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0nWk8f-aHYp",
        "colab_type": "text"
      },
      "source": [
        "#Preproccesing and Modelling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60jz2cRtaTmM",
        "colab_type": "text"
      },
      "source": [
        "The elements in body, url, author, title and comments are objects when they should be string\n",
        "\n",
        "Wrote code to convert each element to string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "attmC0FVa1Ja",
        "colab_type": "text"
      },
      "source": [
        "Let's leave *url* *id* and *created* for a while, maybe I will add them in the future.\n",
        "\n",
        "The body, title and comments will have to be cleaned and there are many uneccesary words and symbols\n",
        "\n",
        "So, the code to clean and remove words in *body*, *title* and *comments* was written using the same apply technique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8AET5RNbs51",
        "colab_type": "text"
      },
      "source": [
        "Train Test split was written. I used *X_test_cv* and *Y_test_cv* for cross-eval.\n",
        "\n",
        "Score and Number of Comments feature is a number so it should be normalized. Wrote the code to normalized using mean, min and max."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G0-oaEUg12F",
        "colab_type": "text"
      },
      "source": [
        "Now, dealing with body, title, comments and author is difficult. They are all just strings.\n",
        "\n",
        "I didn't knew a lot about TF-IDF so my first implementation was wrong which was problematic as took me reading quite a lot to understand that I messed up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgetTbuVhhqp",
        "colab_type": "text"
      },
      "source": [
        "Finally after a lot of time was able to implement TF-IDF correctly.\n",
        "\n",
        "Adding the feature columns thus produced to *X_train* directly, its quite a lot of features.\n",
        "\n",
        "Implemented Random Forest, the accuracy is around 0.68.\n",
        "\n",
        "Linear SVC takes a long time to give results and it has very low accuracy (around 0.1) that it very weird.\n",
        "\n",
        "Tried, Logistic Regression it also has very low accuracy (around 0.09). That is very weird.\n",
        "\n",
        "Tried, Decision Tree it is giving decent accuracy (around 0.58).\n",
        "\n",
        "So, that means Tree based algorithms are giving good accuracy but why not svc.\n",
        "\n",
        "Searched and Studied a lot, found many articles on this. Learned that SVM is not quite good at handling large sparse matrix. So, I converted the sparse matrix into a dense matrix before concatenating."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeSUPfx6kQMl",
        "colab_type": "text"
      },
      "source": [
        "It seems that TF-IDF should not be used with *author* because the frequency for each author would be exceedingly low.\n",
        "Therefore, removed author from cols_to_string.\n",
        "\n",
        "Instead *author* can be used as categorical data, since it is very useful information. Redditors often post same kind of content in a subreddit. So, I can't really drop this feature.\n",
        "\n",
        "Used *get_dummies* on *author* and concatenated them i *X_train*\n",
        "\n",
        "Tried svc and LR again, the accuracy increased significantly (0.65 and 0.66), though still less than Random Forest which jumped to 0.72. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx-uLuGNlrtI",
        "colab_type": "text"
      },
      "source": [
        "Tried Naive Bias, it resulted in an error. The range of scores and number of comments is (-1,1). Converted the range to (0,1).\n",
        "\n",
        "Naive Bias had the lowest accuracy at 0.52.\n",
        "\n",
        "Realized that I could use domain names of the urls as a categorical data. This could reduce overfitting.\n",
        "\n",
        "Used *tldextract* to extract domain name from *url*. Also applied *get_dummies*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV14OtV4mqMj",
        "colab_type": "text"
      },
      "source": [
        "Tried applying ensemble, realized that predict_proba is needed for it. So, can't use in conjungtion with sgd as hinge loss doesn't have pedict_proba, same for SVC.\n",
        "\n",
        "Learned that SVC does have predict_proba, enabled by parameter Probability=True. The accuracy of the ensemble is not that high.\n",
        "\n",
        "Tried, with Random Froest and SGDClassifier the accuracy is less than Random Forest meaning it is actually pulling away from correct answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYwx54npn5Cz",
        "colab_type": "text"
      },
      "source": [
        "Finally decide to use CatBoost even though it might overfit.\n",
        "\n",
        "On running CatBoost code, it gives an error that some columns have same names.\n",
        "\n",
        "Searches for duplicates, found that there are a lot of them. Realize that maybe because tfidf, author and url are all just writing as the feature name with no prefixes. So, maybe someone may have mention a domain name or a redditor's name and it somehow got into tfidf as well thus there could be two columns.\n",
        "\n",
        "Applied prefixes to *url* and *author* by using the *get_dummies* property *prefix*.\n",
        "\n",
        "Applied the same for tfidf by changing the column vector that was passing as a parameter when converting to a DataFrame.\n",
        "\n",
        "Finally ran all the models, accuracy increased a bit and the number of columns reduced.\n",
        "\n",
        "CatBoost had the highest accuracy."
      ]
    }
  ]
}